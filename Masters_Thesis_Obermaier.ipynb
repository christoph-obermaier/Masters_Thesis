{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umformen der UMD31-basierten Genotypdaten in das aktuelle ARS-UCD1.2 Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importieren aller vorerst benötigten Anwendungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen von PLINK Dateiensets `(.bed, .bim, .fam)` aus der vorhandenen `.lgen` Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.getenv('HOME')\n",
    "gts_dir = \"{}/GTS/\".format(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = pd.read_csv(\"{0}/namibia_gts_UMD31.csv\".format(gts_dir), \\\n",
    "                  sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erzeugen der `.lgen` und `.fam` Datei:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts['allele_1']=gts['gt'].str[0]\n",
    "gts['allele_2']=gts['gt'].str[1]\n",
    "gts['fam_id']='0'\n",
    "gts['sire_id']='0'\n",
    "gts['dam_id']='0'\n",
    "gts['sex'] ='0'\n",
    "gts['pht'] = 99999\n",
    "gts[['allele_1','allele_2']] = gts[['allele_1','allele_2']].applymap\\\n",
    "(lambda x: '0' if x=='-' else x)\n",
    "gts[['fam_id','animal_id','snp_id','allele_1','allele_2']].to_csv\\\n",
    "                (\"{0}/namibia_UMD31.lgen\".format(gts_dir), \\\n",
    "                header=None, sep='\\t', index=False)\n",
    "\n",
    "gts.drop_duplicates(['animal_id'])[['fam_id','animal_id',\\\n",
    "                                    'sire_id','dam_id','sex','pht']].\\\n",
    "                                    to_csv(\"{0}/namibia_UMD31.fam\".format(gts_dir), \\\n",
    "                                    header=None, sep='\\t', index=False)\n",
    "\n",
    "#.map file (for UMD31 assembly) is available as namibia_UMD31.map "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --lfile {0}/namibia_UMD31 --out {0}/namibia_UMD31\".format(gts_dir)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`namibia_UMD31.fam` enthält keine Informationen zu den Geschlechtern. <br>\n",
    "Mit der PLINK Funktion `--check-sex` und `--impute-sex` können die Informationen in die `.fam` Datei geschrieben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run in bash shell in gts_dir\n",
    "#plink --cow --bfile namibia_UMD31 --check-sex .5 .7 --out namibia_UMD31\n",
    "#plink --cow --bfile namibia_UMD31 --impute-sex .5 .7 --make-bed --out namibia_UMD31\n",
    "#plink --cow --bfile ansbach_UMD31 --check-sex .5 .7 --out ansbach_UMD31\n",
    "#plink --cow --bfile ansbach_UMD31 --impute-sex .5 .7 --make-bed --out ansbach_UMD31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namibia_sexcheck = pd.read_csv(\"{0}/namibia_UMD31.sexcheck\".\\\n",
    "                               format(gts_dir), delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(namibia_sexcheck['F'], bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lesen der UMD31-basierten `.bim` Dateien für das Ansbach Triesdorfer Rind und Namibia Fleckvieh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bim = pd.read_csv(\"{}/namibia_UMD31.bim\".format(gts_dir), sep='\\t', header=None)\n",
    "#bim = pd.read_csv(\"{}/ansbach_UMD31.bim\".format(gts_dir), sep='\\t', header=None)\n",
    "bim.columns = ['bim_chr','marker','bim_cm','bim_bp', 'bim_A1', 'bim_A2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einlesen der ARS-UCD1.2-basierten Daten (verfügbar durch: [https://www.animalgenome.org/repository/cattle/UMC_bovine_coordinates/](https://www.animalgenome.org/repository/cattle/UMC_bovine_coordinates/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.getenv('HOME')\n",
    "array_dir = \"{0}/REF/ARRAYS\".format(HOME)\n",
    "ARS12_MAP = \"{0}/9913_ARS1.2_58336_SNP50_marker_name_180910.map\".format(array_dir)\n",
    "ARS12_REF = \"{0}/9913_ARS1.2_58336_SNP50_marker_name_180910.REF\".format(array_dir)\n",
    "ARS12_REF_ALLELE = \"{0}/9913_ARS1.2_58336_SNP50_marker_name_180910.REF_ALLELE\".\\\n",
    "                                format(array_dir)\n",
    "MAP = pd.read_csv(ARS12_MAP, sep='\\t', header=None)\n",
    "MAP.columns = ['MAP_chr', 'marker','MAP_cm','MAP_bp']\n",
    "REF = pd.read_csv(ARS12_REF, sep='\\t', header=None)\n",
    "REF.columns=['marker','REF_A','REF_B','REF_A1','REF_A2']\n",
    "REF_A = pd.read_csv(ARS12_REF_ALLELE,sep='\\t',header=None) # Reference allele\n",
    "REF_A.columns=['marker','REF_A_R']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verknüpfen der Informationen aus den UMD31-basierten Daten und der ARS-UCD1.2-basierten Daten anhand der Marker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = pd.merge(MAP,bim)\n",
    "ALL = pd.merge(ALL,REF)\n",
    "ALL = pd.merge(ALL,REF_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prüfen auf andere Allele außer A, C, T und G:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL['REF_A1A2']=ALL.REF_A1 + ALL.REF_A2\n",
    "ALL.groupby(['REF_A1A2'])['REF_A1A2'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL['bim_A1A2'] = ALL.bim_A1 + ALL.bim_A2\n",
    "ALL.groupby(['bim_A1A2'])['bim_A1A2'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"0N\" stellen InDels dar; AT / TA und CG /GC können rechnerisch nicht unterschieden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Überprüfung und Anpassung der Strang-Konformität:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_gt(gt):\n",
    "    c = {'A':'T','C':'G','G':'C','T':'A'}\n",
    "    return ''.join([c[x] for x in list(gt)])\n",
    "new_A1 = []\n",
    "new_A2 = []\n",
    "\n",
    "variants_excluded_namibia = []\n",
    "#variants_excluded_ansbach = []\n",
    "\n",
    "for i in ALL.index:\n",
    "    bim_A1A2 = ALL.iloc[i].bim_A1A2\n",
    "    REF_A1A2 = ALL.iloc[i].REF_A1A2\n",
    "    MAP_chr = ALL.iloc[i].MAP_chr\n",
    "    MAP_bp = ALL.iloc[i].MAP_bp\n",
    "    if bim_A1A2 in ['0A','0C','0G','0T','AT','CG','GC','TA']:\n",
    "        #variants_excluded_namibia.append(\"{0}_{1}\".format(MAP_chr, MAP_bp))\n",
    "        variants_excluded_ansbach.append(\"{0}_{1}\".format(MAP_chr, MAP_bp))\n",
    "        #print(bim_A1A2, MAP_chr, MAP_bp)\n",
    "        new_A1.append(bim_A1A2[0])\n",
    "        new_A2.append(bim_A1A2[1]) \n",
    "    elif bim_A1A2==REF_A1A2:\n",
    "        new_A1.append(bim_A1A2[0])\n",
    "        new_A2.append(bim_A1A2[1])\n",
    "    elif bim_A1A2==REF_A1A2[::-1]:\n",
    "        new_A1.append(bim_A1A2[0])\n",
    "        new_A2.append(bim_A1A2[1])\n",
    "    else:\n",
    "        new_A1.append(c_gt(bim_A1A2)[0])\n",
    "        new_A2.append(c_gt(bim_A1A2)[1])\n",
    " \n",
    "ALL['new_A1'] = new_A1\n",
    "ALL['new_A2'] = new_A2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_excluded_namibia = pd.DataFrame({'variant_id':variants_excluded_namibia})\n",
    "#variants_excluded_ansbach = pd.DataFrame({'variant_id':variants_excluded_ansbach})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen einer Datei `ARS12_REF_NEW` mit Strang-angepassten Allelen und einer Datei mit ausgeschlossenen Varianten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL[['marker','bim_A1','bim_A2','new_A1','new_A2']].\\\n",
    "to_csv('{}/ARS12.REF_NEW_namibia'.format(gts_dir), \\\n",
    "       sep='\\t', header=None, index=False)\n",
    "variants_excluded_namibia[['variant_id']].\\\n",
    "to_csv(\"{0}/variants_excluded_namibia.csv\".format(gts_dir), \\\n",
    "       sep='\\t', header=None, index=False)\n",
    "#ALL[['marker','bim_A1','bim_A2','new_A1','new_A2']].\\\n",
    "#to_csv('{}/ARS12.REF_NEW_ansbach'.format(gts_dir), sep='\\t', header=None, index=False)\n",
    "#variants_excluded_namibia[['variant_id']].\\\n",
    "#to_csv(\"{0}/variants_excluded_ansbach.csv\".format(gts_dir), sep='\\t', \\\n",
    "#header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umwandeln der Markerbezeichung in das Format \"CHR_BP\" (Chromosom_Basenposition):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL['CHR_BP'] = ALL.MAP_chr.astype(str)+'_'+ALL.MAP_bp.astype(str)\n",
    "ALL=ALL.drop_duplicates(['CHR_BP'])\n",
    "ALL[['marker','CHR_BP','REF_A_R']].to_csv('{}/CHR_BP_REF_A'.\\\n",
    "                    format(gts_dir), sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktualisieren aller Datein mit den neuen Informationen mit Hilfe von diversen PLINK --update Befehlen:<br>\n",
    "+ update-chr [filename] {chr col. number} {variant ID col.} {skip}<br>\n",
    "+ update-cm [filename] {cm col. number} {variant ID col.} {skip}<br>\n",
    "+ update-name [filename] {new ID col. number} {old ID col.} {skip}<br>\n",
    "+ update-map [filename] {bp col. number} {variant ID col.} {skip}<br>\n",
    "+ update-alleles [filename]<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {1}/namibia_UMD31 \\\n",
    "--update-chr {0} 1 2 \\\n",
    "--update-map {0} 4 2 \\\n",
    "--update-cm {0} 3 2 \\\n",
    "--update-alleles {1}/ARS12.REF_NEW_namibia \\\n",
    "--make-bed --out {1}/namibia_ARS12\".format(ARS12_MAP, gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {1}/ansbach_UMD31 \\\n",
    "--update-chr {0} 1 2 \\\n",
    "--update-map {0} 4 2 \\\n",
    "--update-cm {0} 3 2 \\\n",
    "--update-alleles {1}/ARS12.REF_NEW_ansbach \\\n",
    "--make-bed --out {1}/ansbach_ARS12\".format(ARS12_MAP, gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/namibia_ARS12 \\\n",
    "--update-name {0}/CHR_BP_REF_A 2 1 \\\n",
    "--make-bed --out {0}/namibia_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/ansbach_ARS12 \\\n",
    "--update-name {0}/CHR_BP_REF_A 2 1 \\\n",
    "--make-bed --out {0}/ansbach_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"cat {0}/CHR_BP_REF_A | cut -f2 > {0}/ARS12_variants\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/namibia_ARS12 \\\n",
    "--extract {0}/ARS12_variants --make-bed --out {0}/namibia_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/ansbach_ARS12 \\\n",
    "--extract {0}/ARS12_variants --make-bed --out {0}/ansbach_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/namibia_ARS12 \\\n",
    "--exclude {0}/variants_excluded_namibia.csv --make-bed --out {0}/namibia_ARS12\".\\\n",
    "format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/ansbach_ARS12 \\\n",
    "--exclude {0}/variants_excluded_ansbach.csv --make-bed \n",
    "--out {0}/ansbach_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/namibia_ARS12 \\\n",
    "--exclude {0}/namibia_ansbach_ARS12-merge.missnp --make-bed \n",
    "--out {0}/namibia_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/ansbach_ARS12 \\\n",
    "--exclude {0}/namibia_ansbach_ARS12-merge.missnp --make-bed \\\n",
    "--out {0}/ansbach_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/namibia_ARS12 --bmerge {0}/ansbach_ARS12 \\\n",
    "--make-bed --out {0}/namibia_ansbach_ARS12\".format(gts_dir)\n",
    "#os.system(cmd)\n",
    "cmd = \"plink --cow --bfile {0}/namibia_ansbach_ARS12 \\\n",
    "--bmerge {0}/fleckvieh_braunvieh_ARS12 --make-bed \\\n",
    "--out {0}/four_pops\".format(gts_dir)\n",
    "#os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein PLINK Dateienset `(five_pops)` ist nun für folgende fünf Populationen verfügbar:<br>\n",
    "+ Original Fleckvieh (früheres Fleckvieh)\n",
    "+ heutiges Fleckvieh\n",
    "+ Namibia Fleckvieh\n",
    "+ Brown Swiss\n",
    "+Holstein Friesian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hauptkomponentenanalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwendung des Moduls `PCA` aus der Anwendung `sklearn` zur Durchführung für drei simulierte Populationen (pop1, pop2, pop3):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gts = np.zeros((1500,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_freqs = np.arange(0.01,1.0,0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "i = 0\n",
    "for i in range(0,1000):\n",
    "    pop1 = np.random.choice(3, 500, p=get_gt_freqs(np.random.choice(allele_freqs)))\n",
    "    pop2 = np.random.choice(3, 500, p=get_gt_freqs(np.random.choice(allele_freqs)))\n",
    "    pop3 = np.random.choice(3, 500, p=get_gt_freqs(np.random.choice(allele_freqs)))\n",
    "    gts[0:500, i] = pop1\n",
    "    gts[500:1000, i] = pop2\n",
    "    gts[1000:1500, i] = pop3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.fit(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pca.transform(gts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Y[:500,0],Y[:500,1], color='blue', label='pop1')\n",
    "plt.scatter(Y[500:1000,0],Y[500:1000,1], color='green', label='pop2')\n",
    "plt.scatter(Y[1000:,0],Y[1000:,1], color='orange', label='pop3')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anwendung der Hauptkomponentenanalyse auf die zu untersuchenden Populationen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/five_pops --geno 0.1 --pca \\\n",
    "--out {0}/five_pops\".format(gts_dir)\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvecs = pd.read_csv(\"{0}/five_pops.eigenvec\".format(gts_dir), \\\n",
    "                        delim_whitespace=True,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=plt.scatter(eigenvecs[2], eigenvecs[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_info = pd.read_excel(\"{0}/fams/pop_info.xlsx\".format(gts_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_info[pop_info['valid']==1].groupby(['pop']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvecs.rename(columns = {1:'iid'}, inplace=True)\n",
    "pop_info.loc[:,'iid']=pop_info.loc[:,'iid'].astype(str)\n",
    "eigenvecs = pd.merge(eigenvecs, pop_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pops0 = ['ansbach','fleckvieh','namibia','orig_fleckvieh','braunvieh','holstein']\n",
    "pops1 = ['ansbach','fleckvieh','namibia','orig_fleckvieh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red','brown','magenta','orange','black','blue']\n",
    "i = 0\n",
    "df0 = eigenvecs[eigenvecs['valid']==1]\n",
    "df0 = eigenvecs\n",
    "for pop in pops0:\n",
    "    df = df0[df0['pop']==pop]\n",
    "    plt.scatter(df[2],df[3],color=colors[i], s=5,label=pop)\n",
    "    i = i + 1\n",
    "plt.title('All populations')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "out=plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['red','brown','magenta','orange','black','blue']\n",
    "i = 0\n",
    "df0 = eigenvecs[eigenvecs['valid']==1]\n",
    "df0 = eigenvecs\n",
    "for pop in pops1:\n",
    "    df = df0[df0['pop']==pop]\n",
    "    plt.scatter(df[2],df[3],color=colors[i], s=15,label=pop)\n",
    "    i = i + 1\n",
    "plt.title('Simmental populations')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "out=plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['black','brown','magenta','orange','black','blue']\n",
    "i = 0\n",
    "df0 = eigenvecs[eigenvecs['valid']==1]\n",
    "#df0 = eigenvecs\n",
    "for pop in pops1:\n",
    "    df = df0[df0['pop']==pop]\n",
    "    plt.scatter(df[2],df[3],color=colors[i], s=15,label=pop)\n",
    "    i = i + 1\n",
    "plt.title('Simmental populations pruned')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "out=plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen eine PLINK Dateiensets für die Namibia Simmental Gruppe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_info = pd.read_excel(\"{0}/fams/pop_info.xlsx\".format(gts_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namibia_simmental = pop_info[(pop_info['pop']=='namibia') & (pop_info['valid']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namibia_simmental[['fid','iid']].to_csv(\"{0}/namibia_simmental.csv\".format(gts_dir), \\\n",
    "                                        sep='\\t', header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/namibia_ARS12 \\\n",
    "--keep {0}/namibia_simmental.csv \\\n",
    "--make-bed --out {0}/namibia_simmental_ARS12\".format(gts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifizierung von SNPs die das Namibia Fleckvieh vom früheren Fleckvieh unterscheiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_info = pd.read_excel(\"{0}/fams/pop_info.xlsx\".format(gts_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origFV_namibiaFV = pop_info[((pop_info['pop1']=='orig_fleckvieh') | \\\n",
    "                             (pop_info['pop1']=='namibia'))  & (pop_info['valid']==1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origFV_namibiaFV[['fid','iid']].to_csv(\"{0}/fams/origFV_namibiaFV.csv\".\\\n",
    "                        format(gts_dir), header=None, index=False,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/five_pops --keep {0}/fams/origFV_namibiaFV.csv \\\n",
    "--geno 0.1 --make-bed --out {0}/origFV_namibiaFV\".format(gts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Umwandeln von PLINK Datei in eine Text-Datei mit den Genotypbezeichnungen 0,1 und 2, codierend nur für die Autosomen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"plink --cow --bfile {0}/origFV_namibiaFV --chr 1-29 --recode A \\\n",
    "--out {0}/origFV_namibiaFV\".format(gts_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_namibia_df = pd.read_csv(\"{0}/origFV_namibiaFV.raw\".format(gts_dir), \\\n",
    "                              delim_whitespace=True, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = pd.Series(orig_namibia_df.columns[6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genotype array\n",
    "X = np.array(orig_namibia_df.iloc[:,6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill nan with allele frequency\n",
    "#Use np.mean does not work - use np.nanmean\n",
    "#Allele frequency is mean of genotype values of each column divided by 2\n",
    "freqs = np.nanmean(X, axis=0)/2\n",
    "na_pos = np.where(np.isnan(X))\n",
    "X[na_pos] = np.take(freqs, na_pos[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(1,11), pca.explained_variance_ratio_[:10])\n",
    "plt.title('PCA variance explained')\n",
    "plt.xlabel('PCA no.')\n",
    "out=plt.ylabel('Proportion of variance explained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinzufügen der Informationen der Rassen zu den Genotyp- und PCA-Datenrahmen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_info = pd.read_excel(\"{0}/fams/pop_info.xlsx\".format(gts_dir))\n",
    "pop_info.rename(columns={'iid':'IID'}, inplace=True)\n",
    "orig_namibia_df.loc[:,'IID'] = orig_namibia_df.loc[:,'IID'].astype(str)\n",
    "pop_info.loc[:,'IID'] = pop_info.loc[:,'IID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(orig_namibia_df, pop_info)[['IID','pop1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df1 = pd.concat([merged,Y_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_fv = Y_df1[Y_df1.pop1=='orig_fleckvieh']\n",
    "namibia = Y_df1[Y_df1.pop1=='namibia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(namibia[0], namibia[1], color='black', label='namibia')\n",
    "plt.scatter(orig_fv[0], orig_fv[1], color='orange', label='orig_fv')\n",
    "out=plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Bedeutung einzelner SNPs bei der Unterscheidung der beiden Rassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_scores=pd.Series(pca.components_[0])\n",
    "loading_scores_sorted = loading_scores.abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kombinieren der `loading_scores` mit den SNP IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP = pd.concat([loading_scores_sorted, snps], \\\n",
    "                axis=1).sort_values([0], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,1000), SNP[0][:1000])\n",
    "plt.title('SNP loadings (1st PC)')\n",
    "plt.xlabel('SNP')\n",
    "out=plt.ylabel('Loading')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusammenfassend trägt nicht nur ein einzelner SNP zur Unterscheidung der beiden Rassen bei, sondern ca. 200 SNPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifizierung von Selektionssignaturen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu Beginn werden die nötigen Pakete, wie `os`, `pandas` und `numpy` importiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HOME` wird als die lokale Umgebung definiert, damit ein Zugriff darauf möglich ist. `gts_dir` ist fortan die Variable mit allen Genotypinformationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.getenv('HOME')\n",
    "gts_dir = \"{}/GTS/\".format(HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Nachfolgenden werden die Genotypinformationen aller Populationen zusammengefasst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_info = pd.read_excel(\"{0}/fams/pop_info.xlsx\".format(gts_dir))\n",
    "pop_info.loc[:,'iid'] = pop_info.loc[:,'iid'].astype(str)\n",
    "five_pops = pd.read_csv(\"{0}/five_pops.fam\".format(gts_dir), delim_whitespace=True, header=None)\n",
    "five_pops.rename(columns={1:'iid'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbei ist darauf zu achten, dass die zweite Spalte in der Datei `five_pops` mit `iid` (individual ID) betitelt wird. Dies wird bei der weiteren Bearbeitung der Daten mit Hilfe des Pakets `PLINK` (v1.90b6.10) [(Purcell et al. 2007)](https://doi.org/10.1086/519795) von Bedeutung.  \n",
    "<br>\n",
    "`pop_info` wird als `.xlsx` und `five_pops` als `.fam` Datei gespeichert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend werden die individuellen Daten der verschiedenen Populationen aus der Datei `pop_info.xlsx` extrahiert und für jede Population z.B. als `namibiaFV.cluster` gespeichert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_info[(pop_info.valid==1)&(pop_info.pop1=='namibia')]\\\n",
    "                            [['iid']].to_csv(\"{0}/namibiaFV.cluster\".\\\n",
    "                            format(gts_dir), sep='\\t', index=False, header=None)\n",
    "pop_info[(pop_info.valid==1)&(pop_info.pop1=='orig_fleckvieh')]\\\n",
    "                            [['iid']].to_csv(\"{0}/origFV.cluster\".\\\n",
    "                            format(gts_dir), sep='\\t', index=False, header=None)\n",
    "pop_info[(pop_info.valid==1)&(pop_info.pop1=='fleckvieh')]\\\n",
    "                            [['iid']].to_csv(\"{0}/FV.cluster\".\\\n",
    "                            format(gts_dir), sep='\\t', index=False, header=None)\n",
    "pop_info[(pop_info.valid==1)&(pop_info.pop1=='holstein')]\\\n",
    "                            [['iid']].to_csv(\"{0}/HF.cluster\".\\\n",
    "                            format(gts_dir), sep='\\t', index=False, header=None)\n",
    "pop_info[(pop_info.valid==1)&(pop_info.pop1=='ansbach')]\\\n",
    "                            [['iid']].to_csv(\"{0}/ansbach.cluster\".\\\n",
    "                            format(gts_dir), sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nächsten Schritt wird ein 'VCF'-Dateienset unter Verwendung der `PLINK` Anwendung erstellt. 'VCF'-Dateien beinhalten komplexe genetische Variationsdaten, die mit Hilfe der Anwendung `VCFtools` (Version 0.1.17) [(Danecek et al. 2011)](https://doi.org/10.1093/bioinformatics/btr330) leicht interpretiert und analysiert werden können.  \n",
    "<br>\n",
    "Desweiteren wird eine neue Variable `ref_dir` definiert, in der sich die Referenzdaten befinden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = \"{}/Forschungsprojekt_Namibia_Fleckvieh/REF/ARRAYS/\".format(HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd  = \"plink \\\n",
    "--cow --bfile {0}/five_pops \\\n",
    "--a2-allele {1}/SNPId_REF_A 2 1 \\\n",
    "--geno 0.1 \\\n",
    "--recode vcf-iid \\\n",
    "--out {0}/five_pops\".format(gts_dir, ref_dir)\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird exemplarisch an aufgeführtem Befehl die Struktur eines `PLINK` Befehls erklärt:\n",
    "\n",
    "*  `plink` : eröffnet den Befehl der Anwendung `PLINK`\n",
    "*  `--cow` : etabliert den Chromosomensatz für Rinder\n",
    "*  `--bfile` : spezifiziert das Dateienset `.bed`, `.bim` und `.fam`\n",
    "*  `--a2-allele` : spezifiziert das A2 Allel als Referenzallel\n",
    "*  `--geno` : hier wird mit der Zahl (0.1) das Maximium an fehlenden Genotypisierung pro SNP festgelegt\n",
    "*  `--recode vcf-iid` : rekreirt eine 'VCF'-Datei ohne IID\n",
    "*  `--out` : spezifiziert den Output Dateinamen  \n",
    "<br>\n",
    "\n",
    "[(Purcell et al. 2007)](https://doi.org/10.1086/519795)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe der Anwendung `VCFtools` mit dem Befehl `--weir-fst-pop <filename>` erhält man die $F_{ST}$ Statistik für die jeweiligen Populationen. Mit den Befehlen `--fst-window-size` und `--fst-window-step` werden die Größe des Fensters und die Länge der Schrittgröße festgelegt.  \n",
    "<br>\n",
    "<br>\n",
    "<p style=\"text-decoration:underline\">Im ersten Fall werden die Populationen Original-Fleckvieh und Namibia-Fleckvieh miteinander betrachtet:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"vcftools \\\n",
    "--vcf {0}/five_pops.vcf \\\n",
    "--weir-fst-pop {0}/origFV.cluster \\\n",
    "--weir-fst-pop {0}/namibiaFV.cluster \\\n",
    "--fst-window-size 2000000 \\\n",
    "--fst-window-step 500000 \\\n",
    "--out {0}/origFV_vs_namibiaFV\".format(gts_dir)\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Im nächsten Fall sind es Fleckvieh und Namibia-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"vcftools \\\n",
    "--vcf {0}/five_pops.vcf \\\n",
    "--weir-fst-pop {0}/FV.cluster \\\n",
    "--weir-fst-pop {0}/namibiaFV.cluster \\\n",
    "--fst-window-size 2000000 \\\n",
    "--fst-window-step 500000 \\\n",
    "--out {0}/FV_vs_namibiaFV\".format(gts_dir)\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Original-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"vcftools \\\n",
    "--vcf {0}/five_pops.vcf \\\n",
    "--weir-fst-pop {0}/FV.cluster \\\n",
    "--weir-fst-pop {0}/origFV.cluster \\\n",
    "--fst-window-size 2000000 \\\n",
    "--fst-window-step 500000 \\\n",
    "--out {0}/FV_vs_origFV\".format(gts_dir)\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Ansbach-Triesdorfer:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = \"vcftools \\\n",
    "--vcf {0}/five_pops.vcf \\\n",
    "--weir-fst-pop {0}/FV.cluster \\\n",
    "--weir-fst-pop {0}/ansbach.cluster \\\n",
    "--fst-window-size 2000000 \\\n",
    "--fst-window-step 500000 \\\n",
    "--out {0}/FV_vs_ansbach\".format(gts_dir)\n",
    "\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt können die Ergebnisse der $F_{ST}$ Statistik ausgelesen werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_fst_origFV_namibia = pd.read_csv(\"{0}/origFV_vs_namibiaFV.windowed.weir.fst\" \\\n",
    "                                     .format(gts_dir),sep='\\t')\n",
    "vcf_fst_FV_namibia     = pd.read_csv(\"{0}/FV_vs_namibiaFV.windowed.weir.fst\" \\\n",
    "                                     .format(gts_dir),sep='\\t')\n",
    "vcf_fst_FV_origFV    = pd.read_csv(\"{0}/FV_vs_origFV.windowed.weir.fst\" \\\n",
    "                                   .format(gts_dir),sep='\\t')\n",
    "vcf_fst_FV_ansbach    = pd.read_csv(\"{0}/FV_vs_ansbach.windowed.weir.fst\" \\\n",
    "                                    .format(gts_dir),sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun ist es möglich die Mittelwerte, Standardabweichungen und die gewichteten Werte für $F_{ST}$ zu entnehmen, die nach [Cockerham und Weir (1984)](https://doi.org/10.2307/2530754) mit Hilfe der Anwendung `VCFtools` berechnet wurden. Die gewichteten Werte für $F_{ST}$ berücksichtigen die Anzahl an SNPs innerhalb eines Fensters [(Wright 1949](https://doi.org/10.1111/j.1469-1809.1949.tb02451.x), [1980)](https://doi.org/10.1016/0047-2484(80)90079-2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_fst_origFV_namibia = vcf_fst_origFV_namibia.WEIGHTED_FST.mean()\n",
    "sd_fst_origFV_namibia = vcf_fst_origFV_namibia.WEIGHTED_FST.std()\n",
    "\n",
    "m_fst_FV_namibia = vcf_fst_FV_namibia.WEIGHTED_FST.mean()\n",
    "sd_fst_FV_namibia = vcf_fst_FV_namibia.WEIGHTED_FST.std()\n",
    "\n",
    "m_fst_FV_origFV = vcf_fst_FV_origFV.WEIGHTED_FST.mean()\n",
    "sd_fst_FV_origFV = vcf_fst_FV_origFV.WEIGHTED_FST.std()\n",
    "\n",
    "m_fst_FV_ansbach = vcf_fst_FV_ansbach.WEIGHTED_FST.mean()\n",
    "sd_fst_FV_ansbach = vcf_fst_FV_ansbach.WEIGHTED_FST.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In den nächsten Schritten werden die $Z$-Werte der $F_{ST}$ Statistik berechnet und dann jeweils als `.csv` Dateien in `gts_dir` gespeichert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_fst_origFV_namibia['Z_FST']= (vcf_fst_origFV_namibia.WEIGHTED_FST-m_fst_origFV_namibia)/sd_fst_origFV_namibia\n",
    "vcf_fst_FV_namibia['Z_FST']= (vcf_fst_FV_namibia.WEIGHTED_FST-m_fst_FV_namibia)/sd_fst_FV_namibia\n",
    "vcf_fst_FV_origFV['Z_FST']= (vcf_fst_FV_origFV.WEIGHTED_FST-m_fst_FV_origFV)/sd_fst_FV_origFV\n",
    "vcf_fst_FV_ansbach['Z_FST']= (vcf_fst_FV_ansbach.WEIGHTED_FST-m_fst_FV_ansbach)/sd_fst_FV_ansbach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_fst_origFV_namibia.to_csv(\"{0}Z_FST_origFV_namibia.csv\".format(gts_dir), sep='\\t',index=False)\n",
    "vcf_fst_FV_namibia.to_csv(\"{0}Z_FST_FV_namibia.csv\".format(gts_dir), sep='\\t',index=False)\n",
    "vcf_fst_FV_origFV.to_csv(\"{0}Z_FST_FV_origFV.csv\".format(gts_dir), sep='\\t',index=False)\n",
    "vcf_fst_FV_ansbach.to_csv(\"{0}Z_FST_FV_ansbach.csv\".format(gts_dir), sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unter Verwendung der Anwendung `matplotlib` (Version 3.1.1) [(Hunter 2007)](https://doi.org/10.1109/MCSE.2007.55) ist es möglich die Daten graphisch darzustellen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,10))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.hist(vcf_fst_origFV_namibia.Z_FST, bins=50)\n",
    "plt.xlabel('$Z$-Werte')\n",
    "plt.title('Original-Fleckvieh - Namibia-Fleckvieh')\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.hist(vcf_fst_FV_namibia.Z_FST, bins=50)\n",
    "plt.xlabel('$Z$-Werte')\n",
    "plt.title('Fleckvieh - Namibia-Fleckvieh')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.hist(vcf_fst_FV_origFV.Z_FST, bins=50)\n",
    "plt.xlabel('$Z$-Werte')\n",
    "plt.title('Fleckvieh - Original-Fleckvieh')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.hist(vcf_fst_FV_ansbach.Z_FST, bins=50)\n",
    "plt.xlabel('$Z$-Werte')\n",
    "plt.title('Fleckvieh - Ansbach-Triesdorfer')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('$Z$-Werte der berechneten $F_{ST}$ Statistik', y=1.03, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe des `Ensembl Project` [(Cunningham et al. 2019)](https://doi.org/10.1093/nar/gky1113) und des darin befindlichen `Biomart` ist es möglich eine aktuelle Genliste für die Tierart Rind zu generieren.  <br>\n",
    "Der `Biomart` ermöglicht eine bedarfsgenaue Einstellung der gewünschten Kriterien und eine dementsprechende Ausgabe der Daten.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Folgenden werden die Daten eingelesen und die Spaltenbezeichnungen angepasst:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_expanded = pd.read_csv(\"{0}/ensembl_bta_genes.txt\".format(gts_dir), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = {\\\n",
    "          'Gene stable ID': 'Ensembl_ID' ,\\\n",
    "          'Gene start (bp)': 'start', \\\n",
    "          'Gene end (bp)': 'end', \\\n",
    "          'Gene name': 'Symbol', \\\n",
    "          'Gene Synonym': 'Synonym', \\\n",
    "          'Chromosome/scaffold name': 'Chromosome', \\\n",
    "          'GOSlim GOA Description': 'GO'}\n",
    "\n",
    "genes_expanded = genes_expanded.rename(columns=rename_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es wird die Ausgabe in so fern angepasst, dass jedes Gen nur einmalig aufgeführt ist und alle Beschreibungen aus der Spalte 'GOSlim GOA Description' aufgeführt werden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listGO = lambda x: \"; \".join(x.iloc[:])\n",
    "getUnique = lambda x: x.iloc[0]\n",
    "genes=genes_expanded.groupby(['Ensembl_ID']).agg({ \\\n",
    "    'Symbol': getUnique, \\\n",
    "    'start': getUnique, \\\n",
    "    'end': getUnique, \\\n",
    "    'Synonym': getUnique, \\\n",
    "    'Chromosome': getUnique, \\\n",
    "    'GO': listGO}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zur leichteren Interpretation in der Genetik wird häufig ein sogenannter Manhattan-Plot verwendet, in dem jedes Chromosom und die dazugehörigen Signalstärken der SNPs verdeutlicht werden.  \n",
    "<br>\n",
    "Deshalb wird im Folgenden eine Anwendung des Manhattan-Plots auf die bereits berechneten $Z$-Werte der $F_{ST}$ Werte erstellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile manhattan_fst.py\n",
    "def manhattan(fst_file):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    from itertools import cycle\n",
    "    import pandas as pd\n",
    "\n",
    "    ps = pd.read_csv(fst_file, delim_whitespace=True)\n",
    "    #ps['BP']= ps['SNP'].apply(lambda x : x.split('_')[1])\n",
    "    ps = ps.rename(columns={'Z_FST':'P','CHROM':'CHR', 'BIN_START':'BP'})\n",
    "\n",
    "    ps = ps.sort_values(['CHR', 'BP'])\n",
    "    ps = ps[ps.CHR>0]\n",
    "    chrs = list(set(list(ps['CHR'])))\n",
    "\n",
    "    #print(len(chrs))\n",
    "\n",
    "    BP_base = 0\n",
    "    colors = cycle(['black', 'grey'])\n",
    "    chr_ticks = []\n",
    "    bonf = 4\n",
    "\n",
    "    plt.figure(figsize=(30,8))\n",
    "\n",
    "    for chr in chrs[:-1]:\n",
    "        col = next(colors)\n",
    "        BP0 = ps[ps['CHR'] == chr].BP\n",
    "        BP  = ps[ps['CHR'] == chr].BP.astype(int)  + BP_base\n",
    "        P = abs(ps[ps['CHR']==chr].P)\n",
    "        chr_tick = ((max(BP) - BP_base)/2) + BP_base\n",
    "        chr_ticks.append(chr_tick)\n",
    "        plt.scatter(BP[P<bonf],P[P<bonf], s=50, alpha=1, color=col, edgecolors='none')\n",
    "        plt.scatter(BP[P>=bonf],P[P>=bonf], s=50, alpha=1, color='red', edgecolors='none')\n",
    "        BP_base = max(BP)\n",
    "\n",
    "    if len(chrs)>30:\n",
    "        CHRS = [\"{0}\".format(x) for x in list(chrs)][:-2]\n",
    "        CHRS.append('X')\n",
    "    else:\n",
    "        CHRS = [\"{0}\".format(x) for x in list(chrs)][:-1]\n",
    "    \n",
    "\n",
    "    plt.xticks(chr_ticks, CHRS, rotation=0)\n",
    "    ax = plt.gca()\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    ax.tick_params(labelsize =15)\n",
    "    plt.xlabel('Chromosome', fontsize=15)\n",
    "    plt.ylabel('Z_FST', fontsize=15)\n",
    "    \n",
    "    plt.hlines(bonf, 0, BP_base, linestyle='dashed',color='grey')\n",
    "\n",
    "    plt.xlim((0, BP_base))\n",
    "    plt.ylim((0,10))\n",
    "\n",
    "    plt.show(block='False')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun ist es möglich die Anwendung `manhattan_fst` zu importieren und auf unsere Rassen anzuwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import manhattan_fst\n",
    "import importlib\n",
    "importlib.reload(manhattan_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Zunächst der Vergleich zwischen Original-Fleckvieh und Namibia-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_fst.manhattan(\"{0}Z_FST_origFV_namibia.csv\".format(gts_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Namibia-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_fst.manhattan(\"{0}Z_FST_FV_namibia.csv\".format(gts_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Original-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_fst.manhattan(\"{0}Z_FST_FV_origFV.csv\".format(gts_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Ansbach-Triesdorfer:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan_fst.manhattan(\"{0}Z_FST_FV_ansbach.csv\".format(gts_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um sich die positionellen Kandidatengene anzeigen zu lassen wird folgende Funktion definiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidates(df, keyword):\n",
    "    top = df[df.Z_FST>=4.0]\n",
    "    top = top.reset_index()\n",
    "    dfs = []\n",
    "    for i in top.index:\n",
    "        chrom = top.iloc[i].CHROM\n",
    "        if chrom != 0:\n",
    "            if chrom == 30:\n",
    "                chrom = \"X\"\n",
    "            else:\n",
    "                chrom = str(int(chrom))\n",
    "            start = top.iloc[i].BIN_START\n",
    "            #print(chrom,start)\n",
    "            out = (genes[(genes.Symbol.notnull()) \\\n",
    "              & (genes.Chromosome==chrom) \\\n",
    "              & (genes.start > start) \\\n",
    "              & (genes.end < start + 2000000) \\\n",
    "              & (genes.GO.str.contains(keyword))])\n",
    "            if not out.empty:\n",
    "                dfs.append(out)\n",
    "    result = pd.concat(dfs)\n",
    "    result = result.drop_duplicates(['Symbol'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Hilfe dieser Funktion lassen sich Kandidatengene mit einem bestimmten Schlüsselwort kombinieren wodurch folglich die Gene, die in Verbindung mit der gewünschten Eigenschaft stehen angezeigt werden. In den nachfolgenden Schritten handelt es sich dabei um die Eigenschaft 'Pigmentation'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Zunächst wieder für den Vergleich Original-Fleckvieh und Namibia-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_candidates(vcf_fst_origFV_namibia, 'pigmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Namibia-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_candidates(vcf_fst_FV_namibia, 'pigmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Original-Fleckvieh:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_candidates(vcf_fst_FV_origFV, 'pigmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-decoration:underline\">Fleckvieh und Ansbach-Triesdorfer:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_candidates(vcf_fst_FV_ansbach, 'pigmentation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berecnnung zum Erhalt der Rasse Frequenzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorbereiten der Daten `GPR143_run7.csv`, `GPR143.csv`, `MITF_run7.csv` und `MITF.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr143_run7 = pd.read_csv('GPR143_run7.csv', sep='\\t', header=None)\n",
    "gpr143 = pd.read_csv('GPR143.csv', sep='\\t', header=None)\n",
    "mitf_run7 = pd.read_csv('MITF_run7.csv', sep='\\t', header=None)\n",
    "mitf = pd.read_csv('MITF.csv', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstellen eines dictionary zur Veränderung der Spaltenbezeichnungen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = \\\n",
    "{0:'Chromosome',\\\n",
    " 1:'Position',\\\n",
    " 2:'Symbol',\\\n",
    " 3:'Region',\\\n",
    " 4:'AA_1',\\\n",
    " 5:'AA_2',\\\n",
    " 6:'Effect',\\\n",
    " 7:'Frequency',\\\n",
    " 8:'RS-Nr.',\\\n",
    " 9:'Source',\\\n",
    "10:'SIFT'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusammenfassen der Daten der TUM und der Daten aus dem RUN7 des 1000 Bullen Projekts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRUN7 = (gpr143_run7, mitf_run7)\n",
    "dataTUM = (gpr143, mitf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anwenden des dictionary auf alle `.csv` Dateien und hinzufügen einer Spalte 'Type' mit der jeweilgen Bezeichnung wo die Daten erhoben wurden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataRUN7:\n",
    "    i.rename(columns=rename_cols, inplace=True)\n",
    "    i['Type']='RUN7'\n",
    "    \n",
    "for j in dataTUM:\n",
    "    j.rename(columns=rename_cols, inplace=True)\n",
    "    j['Type']='TUM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusammenfassen aller vier `.csv` Dateien in einer Datei `allruns.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([gpr143_run7, gpr143, mitf_run7, mitf], ignore_index=True).to_csv('allruns.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigentliche Berechnung der Frequenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allruns = pd.read_csv('allruns.csv', sep='\\t')\n",
    "allruns.loc[:, 'Frequency'] = allruns.loc[:, 'Frequency'].astype(float)\n",
    "allruns.rename(columns={'Region':'Mut_type', 'Type':'Project'}, inplace=True)\n",
    "allruns = allruns.drop(allruns.columns[[0]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MITF_RUN7 = allruns[(allruns.Project=='RUN7') \\\n",
    "                      & (allruns.Symbol=='MITF')\n",
    "                      & ~(allruns.Effect.str.contains('MODI')) \\\n",
    "                      & (allruns.Mut_type != 'synonymous') \\\n",
    "                      & (allruns.Frequency >= 0.001)]\n",
    "mitf_run7_variants = [\"{0}_{1}\".format(x[0],x[1]) for x in zip(MITF_RUN7.Chromosome, MITF_RUN7.Position)]\n",
    "\n",
    "GPR143_RUN7 = allruns[(allruns.Project=='RUN7') \\\n",
    "                      & (allruns.Symbol=='GPR143')\n",
    "                      & ~(allruns.Effect.str.contains('MODI')) \\\n",
    "                      & (allruns.Mut_type != 'synonymous') \\\n",
    "                      & (allruns.Frequency >= 0.001)]\n",
    "gpr143_run7_variants = [\"{0}_{1}\".format(x[0],x[1]) for x in zip(GPR143_RUN7.Chromosome, GPR143_RUN7.Position)]\n",
    "\n",
    "MITF_TUM = allruns[(allruns.Project=='TUM') \\\n",
    "                      & (allruns.Symbol=='MITF')\n",
    "                      & ~(allruns.Effect.str.contains('MODI')) \\\n",
    "                      & (allruns.Mut_type != 'synonymous') \\\n",
    "                      & (allruns.Frequency >= 0.001)]\n",
    "mitf_tum_variants = [\"{0}_{1}\".format(x[0],x[1]) for x in zip(MITF_TUM.Chromosome, MITF_TUM.Position)]\n",
    "\n",
    "GPR143_TUM = allruns[(allruns.Project=='TUM') \\\n",
    "                      & (allruns.Symbol=='GPR143')\n",
    "                      & ~(allruns.Effect.str.contains('MODI')) \\\n",
    "                      & (allruns.Mut_type != 'synonymous') \\\n",
    "                      & (allruns.Frequency >= 0.001)]\n",
    "gpr143_tum_variants = [\"{0}_{1}\".format(x[0],x[1]) for x in zip(GPR143_TUM.Chromosome, GPR143_TUM.Position)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dfs = []\n",
    "for variant in mitf_run7_variants:\n",
    "    chrom_pos = (variant.split('_')[0], variant.split('_')[1])\n",
    "    cur_dir = os.getcwd()\n",
    "    cmd = \"cd /home/{0}/YSERVE/veps_run7/ && exec ./l_get_gts.py {1} {2} > \\\n",
    "    {3}/freqs.csv\".format(local_user,chrom_pos[0], chrom_pos[1], cur_dir)\n",
    "    os.system(cmd)\n",
    "    freqs = pd.read_csv(\"./freqs.csv\", sep='|',header=None, skiprows=5, skipfooter=1, \\\n",
    "                        engine='python')\n",
    "    breed_freq = freqs.loc[:,[1,freqs.shape[1]-3]]\n",
    "    freq_column = breed_freq.columns[-1]\n",
    "    breed_freq.rename(columns={freq_column:'freq'}, inplace=True)\n",
    "    breed_freq['variant']=\"{0}_{1}\".format(chrom_pos[0],chrom_pos[1])\n",
    "    dfs.append(breed_freq)\n",
    "df = pd.concat(dfs)\n",
    "df.loc[:,1] = df[1].str.strip()\n",
    "df.rename(columns = {1:'breed'}, inplace=True)\n",
    "breed_freq = (df.pivot(index='breed', columns='variant'))\n",
    "variants = [x[1] for x in breed_freq.columns]\n",
    "breeds = breed_freq.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit `seaborn` ist es möglich die Daten gut interpretierbar darzustellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurze Erklärung zu nachfolgendem Befehl:  \n",
    "Die Argumente von `sns.heatmap()` sind gut verständlich, doch einige habe ich nicht gleich verstanden:\n",
    "+ `linewidth` und `linecolor` geben ein Grid an (macht es meiner Meinung nach übersichtlicher)\n",
    "+ `annot=True` macht die Frequenzen, also die direkten Zahlenwerte sichtbar\n",
    "+ `fmt=.3f` gibt an wie viele Stellen der Frequenzen angegeben werden; hier: 3 Nachkommastellen als Datentyp float\n",
    "+ `cmap=YlOrRd` gibt die Farbpalette an\n",
    "+ `mask=breed_freq==0.000` maskiert alle Werte gleich 0.000, kann auch mit < oder > gemacht werden\n",
    "\n",
    "Die obere und untere Reihe waren nur halb sichtbar, was mit folgenden Befehlen gelöst wurde:\n",
    "+ `bottom, top = ax.get_ylim()`\n",
    "+ `ax.set_ylim(bottom + 0.5, top - 0.5)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,25))\n",
    "plt.title('Frequencies of MITF_RUN7 variants', size=15)\n",
    "ax = sns.heatmap(breed_freq, linewidths=0.1, linecolor='black', annot=True, fmt='.3f',\\\n",
    "                 cmap='YlOrRd', mask=breed_freq==0.000)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "ax.set(xlabel='Variants', ylabel='Breed')\n",
    "plt.savefig('Freq_heatmap_MITF_RUN7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dfs = []\n",
    "for variant in gpr143_run7_variants:\n",
    "    chrom_pos = (variant.split('_')[0], variant.split('_')[1])\n",
    "    cur_dir = os.getcwd()\n",
    "    cmd = \"cd /home/{0}/YSERVE/veps_run7/ && exec ./l_get_gts.py {1} {2} > \\\n",
    "    {3}/freqs.csv\".format(local_user,chrom_pos[0], chrom_pos[1], cur_dir)\n",
    "    os.system(cmd)\n",
    "    freqs = pd.read_csv(\"./freqs.csv\", sep='|',header=None, skiprows=5, skipfooter=1, \\\n",
    "                        engine='python')\n",
    "    breed_freq = freqs.loc[:,[1,freqs.shape[1]-3]]\n",
    "    freq_column = breed_freq.columns[-1]\n",
    "    breed_freq.rename(columns={freq_column:'freq'}, inplace=True)\n",
    "    breed_freq['variant']=\"{0}_{1}\".format(chrom_pos[0],chrom_pos[1])\n",
    "    dfs.append(breed_freq)\n",
    "df = pd.concat(dfs)\n",
    "df.loc[:,1] = df[1].str.strip()\n",
    "df.rename(columns = {1:'breed'}, inplace=True)\n",
    "breed_freq = (df.pivot(index='breed', columns='variant'))\n",
    "variants = [x[1] for x in breed_freq.columns]\n",
    "breeds = breed_freq.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,30))\n",
    "plt.title('Frequencies of GPR143_RUN7 variants', size=15)\n",
    "ax = sns.heatmap(breed_freq, linewidths=0.1, linecolor='black', annot=True, fmt='.3f', \\\n",
    "                 cmap='YlOrRd', mask=breed_freq==0.000)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "ax.set(xlabel='Variants', ylabel='Breed')\n",
    "plt.savefig('Freq_heatmap_GPR143_RUN7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dfs = []\n",
    "for variant in mitf_tum_variants:\n",
    "    chrom_pos = (variant.split('_')[0], variant.split('_')[1])\n",
    "    cur_dir = os.getcwd()\n",
    "    cmd = \"cd /home/{0}/YSERVE/veps/ && exec ./l_get_gts.py {1} {2} > \\\n",
    "    {3}/freqs.csv\".format(local_user,chrom_pos[0], chrom_pos[1], cur_dir)\n",
    "    os.system(cmd)\n",
    "    freqs = pd.read_csv(\"./freqs.csv\", sep='|',header=None, skiprows=5, skipfooter=1, \\\n",
    "                        engine='python')\n",
    "    breed_freq = freqs.loc[:,[1,freqs.shape[1]-3]]\n",
    "    freq_column = breed_freq.columns[-1]\n",
    "    breed_freq.rename(columns={freq_column:'freq'}, inplace=True)\n",
    "    breed_freq['variant']=\"{0}_{1}\".format(chrom_pos[0],chrom_pos[1])\n",
    "    dfs.append(breed_freq)\n",
    "df = pd.concat(dfs)\n",
    "df.loc[:,1] = df[1].str.strip()\n",
    "df.rename(columns = {1:'breed'}, inplace=True)\n",
    "breed_freq = (df.pivot(index='breed', columns='variant'))\n",
    "variants = [x[1] for x in breed_freq.columns]\n",
    "breeds = breed_freq.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,20))\n",
    "plt.title('Frequencies of MITF_TUM variants', size=15)\n",
    "ax = sns.heatmap(breed_freq, linewidths=0.1, linecolor='black', annot=True, fmt='.3f', \\\n",
    "                 cmap='YlOrRd', mask=breed_freq==0.000)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "ax.set(xlabel='Variants', ylabel='Breed')\n",
    "plt.savefig('Freq_heatmap_MITF_TUM.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "dfs = []\n",
    "for variant in gpr143_tum_variants:\n",
    "    chrom_pos = (variant.split('_')[0], variant.split('_')[1])\n",
    "    cur_dir = os.getcwd()\n",
    "    cmd = \"cd /home/{0}/YSERVE/veps/ && exec ./l_get_gts.py {1} {2} > \\\n",
    "    {3}/freqs.csv\".format(local_user,chrom_pos[0], chrom_pos[1], cur_dir)\n",
    "    os.system(cmd)\n",
    "    freqs = pd.read_csv(\"./freqs.csv\", sep='|',header=None, skiprows=5, skipfooter=1, \\\n",
    "                        engine='python')\n",
    "    breed_freq = freqs.loc[:,[1,freqs.shape[1]-3]]\n",
    "    freq_column = breed_freq.columns[-1]\n",
    "    breed_freq.rename(columns={freq_column:'freq'}, inplace=True)\n",
    "    breed_freq['variant']=\"{0}_{1}\".format(chrom_pos[0],chrom_pos[1])\n",
    "    dfs.append(breed_freq)\n",
    "df = pd.concat(dfs)\n",
    "df.loc[:,1] = df[1].str.strip()\n",
    "df.rename(columns = {1:'breed'}, inplace=True)\n",
    "breed_freq = (df.pivot(index='breed', columns='variant'))\n",
    "variants = [x[1] for x in breed_freq.columns]\n",
    "breeds = breed_freq.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,15))\n",
    "plt.title('Frequencies of GPR143_TUM variants', size=15)\n",
    "ax = sns.heatmap(breed_freq, linewidths=0.1, linecolor='black', annot=True, fmt='.3f', \\\n",
    "                 cmap='YlOrRd', mask=breed_freq==0.000)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "ax.set(xlabel='Variants', ylabel='Breed')\n",
    "plt.savefig('Freq_heatmap_GPR143_TUM.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung der Allelfrequenzen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bemerkung: erste eckige Klammer sind alle homozygoten Tiere; die zweite eckige Klammer alle heterozygoten Tiere; die dritte eckige Klammer alle alternativ homzygoten Tiere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für alle Tiere\n",
    "gts = np.array([[57],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Ansbach Triesdorfer Rind\n",
    "gts = np.array([[29],[1],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# für Namibia Fleckvieh\n",
    "gts = np.array([[28],[0],[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ((gts[0]*2)+gts[1])/(2*sum(gts))\n",
    "q = 1-p\n",
    "print (p,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung des Hardy-Weinberg Gleichgewichts und der Chi-Quadrat Statistik aus den Allelfrequenzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hwe(gts):\n",
    "    p = ((gts[0]*2)+gts[1])/(2*sum(gts))\n",
    "    q = 1-p\n",
    "    print (p,q)\n",
    "    e_gts = np.array([p**2, 2*p*q,q**2])*sum(gts)\n",
    "    stat = sum(((gts-e_gts)**2)/(e_gts))\n",
    "    print (stat)\n",
    "    return 1-stats.chi2.cdf(stats.chisquare(gts,e_gts)[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwe(gts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung des Fisher's Exact Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bemerkung: In den eckigen Klammern befinden sich jeweils die Anzahl an homozygoten und heterozygoten Tieren der beiden Subpopulationen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oddsratio, pvalue = stats.fisher_exact([[32, 2], [27, 7]])\n",
    "pvalue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
